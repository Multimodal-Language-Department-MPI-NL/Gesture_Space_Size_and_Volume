{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1> Quantitative Measures for Gesture Space </h1>\n",
        "\n",
        "In this module, we learn different ways to measure the space used by gestures. This notebook is based on https://envisionbox.org/embedded_Analysis_kinematic_features_module.html\n",
        "\n",
        "<h2> Overview of the script </h2>\n",
        "\n",
        "1. Vertical Amplitude\n",
        "2. McNeillian Space\n",
        "3. Volumetric Space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('p:/shared/FOCUS-GROUPS/Gesture-Kinematics/gesture_space_compuation/1130_JS_body.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_MP_to_OP(df_MP):\n",
        "    # first we create a dictionary that maps the names in our MediaPipe output to the names in our OpenPose output\n",
        "    conv_dict = {\"RIGHT_WRIST\":\"R_Hand\", \"LEFT_WRIST\":\"L_Hand\",\"NOSE\":\"Nose\",\"RIGHT_ELBOW\":\"RElb\",\"LEFT_ELBOW\":\"LElb\",\"RIGHT_HIP\":\"RHip\",\"LEFT_HIP\":\"LHip\", \"LEFT_EYE\":\"LEye\",\"RIGHT_EYE\":\"REye\"}\n",
        "    \n",
        "    OP_df = pd.DataFrame()\n",
        "    \n",
        "    for key in conv_dict:\n",
        "        \n",
        "        OP_df[conv_dict[key]] = [[row[\"X_\"+key],row[\"Y_\"+key],row[\"Z_\"+key]] for _,row in df_MP.iterrows()]\n",
        "    OP_df[\"time\"] = df_MP[\"time\"].copy()\n",
        "    \n",
        "    # NOTE: not all methods track the exact same keypoints. For some of our calculations we need a Neck point, and a Mid-Hip Point.\n",
        "    # We need to calculate these based on others\n",
        "    OP_df[\"Neck\"] = [[np.mean([row[\"X_LEFT_SHOULDER\"],row[\"Y_RIGHT_SHOULDER\"]]),np.mean([row[\"X_LEFT_SHOULDER\"],row[\"Y_LEFT_SHOULDER\"]]),row[\"Z_RIGHT_SHOULDER\"] ] for _, row in df_MP.iterrows()]\n",
        "    OP_df[\"MidHip\"] = [[np.mean([row[\"X_LEFT_HIP\"],row[\"X_RIGHT_HIP\"]]),np.mean([row[\"Y_LEFT_HIP\"],row[\"Y_LEFT_HIP\"]]),row[\"Z_RIGHT_HIP\"] ] for _, row in df_MP.iterrows()]\n",
        "    return OP_df\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_OP = convert_MP_to_OP(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_OP.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2> Vertical Amplitude </h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This first feature, vertical amplitude, will calculate the maximum amplitude of the hands. It does this not in an image-specific way (such as pixels, meters), but in a person-specific way, giving you the max height relative to the body of the person performing the gesture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calc_vert_height(df, hand):\n",
        "    # Vertical amplitude\n",
        "    # H: 0 = below midline;\n",
        "    #    1 = between midline and middle-upper body;\n",
        "    #    2 = above middle-upper body, but below shoulders;\n",
        "    #    3 = between shoulders nad middle of face;\n",
        "    #    4 = between middle of face and top of head;\n",
        "    #    5 = above head\n",
        "\n",
        "    H = []\n",
        "    for index, frame in df.iterrows():\n",
        "        SP_mid = ((df.loc[index, \"Neck\"][1] - df.loc[index, \"MidHip\"][1]) / 2) + df.loc[index, \"MidHip\"][1]\n",
        "        Mid_up = ((df.loc[index, \"Nose\"][1] - df.loc[index, \"Neck\"][1]) / 2) + df.loc[index, \"Neck\"][1]\n",
        "        Eye_mid = (df.loc[index, \"REye\"][1] + df.loc[index, \"LEye\"][1] / 2)  # mean of the two eyes vert height\n",
        "        Head_TP = ((df.loc[index, \"Nose\"][1] - Eye_mid) * 2) + df.loc[index, \"Nose\"][1]\n",
        "\n",
        "        if hand == \"B\":\n",
        "            hand_height = max([df.loc[index, \"R_Hand\"][1], df.loc[index, \"L_Hand\"][1]])\n",
        "        else:\n",
        "            hand_str = hand + \"_Hand\"\n",
        "            hand_height = df.loc[index][hand_str][1]\n",
        "\n",
        "        if hand_height > SP_mid:\n",
        "            if hand_height > Mid_up:\n",
        "                if hand_height > df.loc[index, \"Neck\"][1]:\n",
        "                    if hand_height > df.loc[index, \"Nose\"][1] :\n",
        "                        if hand_height > Head_TP:\n",
        "                            H.append(5)\n",
        "                        else:\n",
        "                            H.append(4)\n",
        "                    else:\n",
        "                        H.append(3)\n",
        "                else:\n",
        "                    H.append(2)\n",
        "            else:\n",
        "                H.append(1)\n",
        "        else:\n",
        "            H.append(0)\n",
        "    MaxHeight = max(H)\n",
        "    return MaxHeight\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_height_R = calc_vert_height(df_OP, \"B\")\n",
        "\n",
        "print(\"Max height for the two hands: \" + str(max_height_R))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get a value of 1, indicating that the maximum height (considering both hands) is \"between midline and middle-upper body\". The function gives the option of indicating whether you want to consider one hand, or both, which can be useful if you\\'ve annotated the handedness of a gesture. In this case, we know that this is a two-handed gesture, so we\\'ll use the \"B\" tag for our calculations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>McNeillian Space</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "What if we want to be more specific? Those familiar with gesture studies will likely have seen David McNeill\\'s (1992) delineation of <i>gesture space</i>. \n",
        "<br><img src=\\\"./gesture_space.jpg\\\"></center><br>\n",
        "The gesture space offers some interesting insights into the way we use visual space during a gesture. For example, is it produces primarily directly in front of us? Do we cover a lot of space around us? How \\'expansive\\' is the gesture? However, these can be difficult or time consuming to manually annotate, and even more so if the video angle is not straight ahead. However, we can implement this using our motion tracking keypoints.<br>\n",
        "This requires several calculations, such as defining the grid seen in the image above, checking the position of the hands in relation to the grid, and calculating different features about where the hands moved, which areas they occupied, etc. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "def calc_mcneillian_space(df, hand_idx):\n",
        "    # this calls the define_mcneillian_grid function for each frame, then assign the hand to one space for each frame\n",
        "    # output:\n",
        "    # space_use - how many unique spaces were traversed\n",
        "    # mcneillian_max - outer-most main space entered\n",
        "    # mcneillian_mode - which main space was primarily used\n",
        "    # 1 = Center-center\n",
        "    # 2 = Center\n",
        "    # 3 = Periphery\n",
        "    # 4 = Extra-Periphery\n",
        "    # subsections for periphery and extra periphery:\n",
        "    # 1 = upper right\n",
        "    # 2 = right\n",
        "    # 3 = lower right\n",
        "    # 4 = lower\n",
        "    # 5 = lower left\n",
        "    # 6 = left\n",
        "    # 7 = upper left\n",
        "    # 8 = upper\n",
        "    if hand_idx == 'B':\n",
        "        hands = ['L_Hand','R_Hand']\n",
        "    else:\n",
        "        hands = [hand_idx + '_Hand']\n",
        "    # compare, at each frame, each hand to the (sub)section limits, going from inner to outer, clockwise\n",
        "    for hand in hands:\n",
        "        Space = []\n",
        "\n",
        "        for frame in range(len(df)):\n",
        "\n",
        "            cc_xmin, cc_xmax, cc_ymin, cc_ymax, c_xmin, c_xmax, c_ymin, c_ymax, p_xmin, p_xmax, p_ymin, p_ymax = \\\n",
        "            define_mcneillian_grid(df, frame)\n",
        "            # centre-centre\n",
        "            if cc_xmin < df[hand][frame][0] < cc_xmax and cc_ymin < df[hand][frame][1] < cc_ymax:\n",
        "                Space.append(1)\n",
        "            # centre\n",
        "            elif c_xmin < df[hand][frame][0] < c_xmax and c_ymin < df[hand][frame][1] < c_ymax:\n",
        "                Space.append(2)\n",
        "            # periph\n",
        "            elif p_xmin < df[hand][frame][0] < p_xmax and p_ymin < df[hand][frame][1] < p_ymax:\n",
        "                # if it\\'s in the periphery, we need to also get the subsection\n",
        "                # first, is it on the right side?\n",
        "                if cc_xmax < df[hand][frame][0]:\n",
        "                    # if so, we narrow down the y location\n",
        "                    if cc_ymax < df[hand][frame][1]:\n",
        "                        Space.append(31)\n",
        "                    elif cc_ymin < df[hand][frame][1]:\n",
        "                        Space.append(32)\n",
        "                    else:\n",
        "                        Space.append(33)\n",
        "                elif cc_xmin < df[hand][frame][0]:\n",
        "                    if c_ymax < df[hand][frame][1]:\n",
        "                        Space.append(38)\n",
        "                    else:\n",
        "                        Space.append(34)\n",
        "                else:\n",
        "                    if cc_ymax < df[hand][frame][1]:\n",
        "                        Space.append(37)\n",
        "                    elif cc_ymin < df[hand][frame][1]:\n",
        "                        Space.append(36)\n",
        "                    else:\n",
        "                        Space.append(35)\n",
        "            else:  # if it\\'s not periphery, it has to be extra periphery. We just need to get subsections\n",
        "                if c_xmax < df[hand][frame][0]:\n",
        "                    if cc_ymax < df[hand][frame][1]:\n",
        "                        Space.append(41)\n",
        "                    elif cc_ymin < df[hand][frame][1]:\n",
        "                        Space.append(42)\n",
        "                    else:\n",
        "                        Space.append(43)\n",
        "                elif cc_xmin < df[hand][frame][0]:\n",
        "                    if c_ymax < df[hand][frame][1]:\n",
        "                        Space.append(48)\n",
        "                    else:\n",
        "                        Space.append(44)\n",
        "                else:\n",
        "                    if c_ymax < df[hand][frame][1]:\n",
        "                        Space.append(47)\n",
        "                    elif c_ymin < df[hand][frame][1]:\n",
        "                        Space.append(46)\n",
        "                    else:\n",
        "                        Space.append(45)\n",
        "        if hand == 'L_Hand':\n",
        "            Space_L = Space\n",
        "        else:\n",
        "            Space_R = Space\n",
        "\n",
        "    # how many spaces used?\n",
        "    if hand_idx == 'L' or hand_idx == 'B':\n",
        "        space_use_L = len(set(Space_L))\n",
        "        if max(Space_L) > 40:\n",
        "            mcneillian_maxL = 4\n",
        "        elif max(Space_L) > 30:\n",
        "            mcneillian_maxL = 3\n",
        "        else:\n",
        "            mcneillian_maxL = max(Space_L)\n",
        "        # which main space was most used?\n",
        "        mcneillian_modeL = get_mcneillian_mode(Space_L)\n",
        "    else:\n",
        "        space_use_L = 'NA'\n",
        "        mcneillian_maxL = 'NA'\n",
        "        mcneillian_modeL = 'NA'\n",
        "\n",
        "    if hand_idx == 'R' or hand_idx == 'B':\n",
        "        space_use_R = len(set(Space_R))\n",
        "        # maximum distance (main spaces)\n",
        "        if max(Space_R) > 40:\n",
        "            mcneillian_maxR = 4\n",
        "        elif max(Space_R) > 30:\n",
        "            mcneillian_maxR = 3\n",
        "        else:\n",
        "            mcneillian_maxR = max(Space_R)\n",
        "        # which main space was most used?\n",
        "        mcneillian_modeR = get_mcneillian_mode(Space_R)\n",
        "    else:\n",
        "        space_use_R = 'NA'\n",
        "        mcneillian_maxR = 'NA'\n",
        "        mcneillian_modeR = 'NA'\n",
        "\n",
        "    return space_use_L, space_use_R, mcneillian_maxL, mcneillian_maxR, mcneillian_modeL, mcneillian_modeR\n",
        "\n",
        "\n",
        "def get_mcneillian_mode(spaces):\n",
        "    mainspace = []\n",
        "    for space in spaces:\n",
        "        if space > 40:\n",
        "            mainspace.append(4)\n",
        "        elif space > 30:\n",
        "            mainspace.append(3)\n",
        "        else:\n",
        "            mainspace.append(space)\n",
        "\n",
        "    mcneillian_mode = statistics.mode(mainspace)\n",
        "    return mcneillian_mode\n",
        "\n",
        "def define_mcneillian_grid(df, frame):\n",
        "    # define the grid based on a single frame, output xmin,xmax, ymin, ymax for each main section\n",
        "    # subsections can all be found based on these boundaries\n",
        "    bodycent = df['Neck'][frame][1] - (df['Neck'][frame][1] - df['MidHip'][frame][1])/2\n",
        "    face_width = (df['LEye'][frame][0] - df['REye'][frame][0])*2\n",
        "    body_width = df['LHip'][frame][0] - df['RHip'][frame][0]\n",
        "\n",
        "    # define boundaries for center-center\n",
        "    cc_xmin = df['RHip'][frame][0]\n",
        "    cc_xmax = df['LHip'][frame][0]\n",
        "    cc_len = cc_xmax - cc_xmin\n",
        "    cc_ymin = bodycent - cc_len/2\n",
        "    cc_ymax = bodycent + cc_len/2\n",
        "\n",
        "    # define boundaries for center\n",
        "    c_xmin = df['RHip'][frame][0] - body_width/2\n",
        "    c_xmax = df['LHip'][frame][0] + body_width/2\n",
        "    c_len = c_xmax - c_xmin\n",
        "    c_ymin = bodycent - c_len/2\n",
        "    c_ymax = bodycent + c_len/2\n",
        "\n",
        "    # define boundaries of periphery\n",
        "    p_ymax = df['LEye'][frame][1] + (df['LEye'][frame][1] - df['Nose'][frame][1])\n",
        "    p_ymin = bodycent - (p_ymax - bodycent) # make the box symmetrical around the body center\n",
        "    p_xmin = c_xmin - face_width\n",
        "    p_xmax = c_xmax + face_width\n",
        "\n",
        "    return  cc_xmin, cc_xmax, cc_ymin, cc_ymax, c_xmin, c_xmax, c_ymin, c_ymax, p_xmin, p_xmax, p_ymin, p_ymax\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "space_use_L, space_use_R, mcneillian_maxL, mcneillian_maxR, mcneillian_modeL, mcneillian_modeR = calc_mcneillian_space(df_OP, \"B\")\n",
        "\n",
        "print(\"Number of spaces uses by the right hand: \" + str(space_use_R))\n",
        "print(\"Most peripheral space used by right hand: \" + str(mcneillian_maxR))\n",
        "print(\"Right hand spent most time in space number: \" + str(mcneillian_modeR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see, 4 different spaces were used (centre, 2 in periphery, and 1 in extra-periphery, in this case). Additionally, space 4 (extra periphery) is both the maximally peripheral space used, and where the right hand spent mos of its time.<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Volumetric Space</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another way to think about the space used is to calculate the volumetric space. Imagine that at the beginning of your annotation, we draw a cube (if the data is 3D, otherwise a box) around the hands, such that the hands position along the x-axis forms the outer side-limits of the cube/box, and their position on the y-axis forms the upper and lower limits. Our cube/box will therefore be quite flat at the beginning. But if we update and expand this cube/box with each frame, we can get an idea of the dynamic space that is used during a gesture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calc_volume_size(df, hand):\n",
        "    # calculates the volumetric size of the gesture, ie how much visual space was utlized by the hands\n",
        "    # for 3D data, this is actual volume (ie. using z-axis), for 2D this is area, using only x and y\\\n",
        "    # first we check if we should use one or both hands for calculating the initial boundaries\n",
        "    if hand == 'B':\n",
        "        x_max = max([df['R_Hand'][0][0], df['L_Hand'][0][0]])\n",
        "        x_min = min([df['R_Hand'][0][0], df['L_Hand'][0][0]])\n",
        "        y_max = max([df['R_Hand'][0][0], df['L_Hand'][0][1]])\n",
        "        y_min = min([df['R_Hand'][0][0], df['L_Hand'][0][1]])\n",
        "    else:\n",
        "        hand_str = hand + '_Hand'\n",
        "        x_min = df[hand_str][0][0]\n",
        "        x_max = df[hand_str][0][0]\n",
        "        y_min = df[hand_str][0][1]\n",
        "        y_max = df[hand_str][0][1]\n",
        "    # then we check if it\\'s 3D or 2D data\n",
        "    if len(df['R_Hand'][0]) > 2:\n",
        "        if hand == 'B':\n",
        "            z_max = max([df['R_Hand'][0][2], df['L_Hand'][0][2]])\n",
        "            z_min = min([df['R_Hand'][0][2], df['L_Hand'][0][2]])\n",
        "        else:\n",
        "            z_min = df[hand_str][0][2]\n",
        "            z_max = df[hand_str][0][2]\n",
        "    # at each frame, compare the current min and max with the previous, to ultimately find the outer values\n",
        "    if hand == 'B':\n",
        "        hand_list = ['R_Hand', 'L_Hand']\n",
        "    else:\n",
        "        hand_list = [hand_str]\n",
        "\n",
        "    for frame in range(1, len(df)):\n",
        "        for hand_idx in hand_list:\n",
        "            if df[hand_idx][frame][0] < x_min:\n",
        "                x_min = df[hand_idx][frame][0]\n",
        "            if df[hand_idx][frame][0] > x_max:\n",
        "                x_max = df[hand_idx][frame][0]\n",
        "            if df[hand_idx][frame][0] < y_min:\n",
        "                y_min = df[hand_idx][frame][1]\n",
        "            if df[hand_idx][frame][0] > y_max:\n",
        "                y_max = df[hand_idx][frame][1]\n",
        "            if len(df[hand_idx][0]) > 2:\n",
        "                if df[hand_idx][frame][0] < z_min:\n",
        "                    z_min = df[hand_idx][frame][2]\n",
        "                if df[hand_idx][frame][0] > z_max:\n",
        "                    z_max = df[hand_idx][frame][2]\n",
        "\n",
        "    if len(df['R_Hand'][0]) > 2:\n",
        "        # get range\n",
        "        x_len = x_max - x_min\n",
        "        y_len = y_max - y_min\n",
        "        z_len = z_max - z_min\n",
        "        # get volume\n",
        "        vol = x_len * y_len * z_len\n",
        "    else:\n",
        "        x_len = x_max - x_min\n",
        "        y_len = y_max - y_min\n",
        "        # get area (ie volume)\n",
        "        vol = x_len * y_len\n",
        "    return vol\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "volume = calc_volume_size(df_OP,'B')\n",
        "print('Volumetric space of the two hands: ' + str(volume) + \" meters\")\n",
        "volume_R = calc_volume_size(df_OP,'R')\n",
        "print('Volumetric space of the right hand: ' + str(volume_R) + \" meters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2> Working with Multiple Files </h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pympi-ling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pympi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "path = 'p:/shared/FOCUS-GROUPS/Gesture-Kinematics/gesture_space_compuation/'\n",
        "\n",
        "MT_files = [file for file in os.listdir(path) if file.endswith(\".csv\")] #Reading list of motion tracking files from the folder\n",
        "eaf_files = [file for file in os.listdir(path) if file.endswith(\".eaf\")] #Reading list of ELAN files from the folder\n",
        "\n",
        "results_df = pd.DataFrame(columns = [\"file\", \"gesture\", \n",
        "                            \n",
        "                            \"MN_mode_L\",\"MN_mode_R\", \"volume_B\", \"volume_R\", \"volume_L\"]) #Creating an empty dataframe to store the results\n",
        "\n",
        "for MT_file in MT_files: #Iterating through each motion tracking file \n",
        "    print('Processing file: ' + MT_file)\n",
        "\n",
        "    df_MT = pd.read_csv(path + MT_file)\n",
        "    df_OP = convert_MP_to_OP(df_MT) #Converting the MediaPipe output to OpenPose output (only the required columns)\n",
        "\n",
        "    eaf_file = [eaf_file for eaf_file in eaf_files if eaf_file.startswith(MT_file.split(\"_\")[0])][0]           \n",
        "\n",
        "    eafob = pympi.Elan.Eaf(path + eaf_file) #Reading the corresponding ELAN file\n",
        "\n",
        "    # make sure you set the name of the tier where the annotations of interest are located\n",
        "    gesture_annots = eafob.get_annotation_data_for_tier(\"Director_Speech\")\n",
        "\n",
        "    # then we can look through each annotation, and calculate our kinematic values\n",
        "    file_list = []\n",
        "    g_index_list = []\n",
        "    PV_R_list = []\n",
        "\n",
        "    mode_L_list = []\n",
        "    mode_R_list = []\n",
        "\n",
        "    volume_B_list = []\n",
        "    volume_R_list = []\n",
        "    volume_L_list = []\n",
        "\n",
        "    g_index = 1\n",
        "    for annot in gesture_annots:\n",
        "        # this first line just takes the rows that correspond to our annotation\n",
        "        g_data = df_OP[(df_OP.time >= annot[0]) & (df_OP.time <= annot[1])]\n",
        "        g_data.reset_index(inplace=True)\n",
        "        \n",
        "        if len(g_data) > 10:\n",
        "        \n",
        "            \n",
        "            space_use_L, space_use_R, mcneillian_maxL, mcneillian_maxR, mcneillian_modeL, mcneillian_modeR = calc_mcneillian_space(g_data, \"B\")\n",
        "\n",
        "            volume_B = calc_volume_size(g_data,'B')\n",
        "            volume_R = calc_volume_size(g_data,'R')\n",
        "            volume_L = calc_volume_size(g_data,'L')\n",
        "\n",
        "            # now store them all in a dataframe\n",
        "            file_list.append(MT_file)\n",
        "            g_index_list.append(g_index)\n",
        "        \n",
        "            mode_L_list.append(mcneillian_modeL)\n",
        "            mode_R_list.append(mcneillian_modeR)\n",
        "\n",
        "            volume_B_list.append(volume_B)\n",
        "            volume_R_list.append(volume_R)\n",
        "            volume_L_list.append(volume_L)\n",
        "\n",
        "            g_index += 1\n",
        "        \n",
        "    results_df = pd.concat([results_df, pd.DataFrame(np.column_stack([file_list, g_index_list,\n",
        "                                    \n",
        "                                    mode_L_list,  mode_R_list, volume_B_list, volume_R_list, volume_L_list]), columns = [\"file\", \"gesture\", \n",
        "                            \n",
        "                            \"MN_mode_L\",\"MN_mode_R\", \"volume_B\", \"volume_R\", \"volume_L\"])])\n",
        "                    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !conda install anaconda::openpyxl #Go to terminal and run this command to install openpyxl package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.to_excel('space_results.xlsx')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
